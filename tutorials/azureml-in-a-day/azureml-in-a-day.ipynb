{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 日で理解する AzureML\n",
    "\n",
    "データ サイエンティストが Azure Machine Learning (Azure ML) を使用してモデルをトレーニングし、そのモデルを予測に使用する方法を学びます。 このチュートリアルは、Azure ML の中心的な概念とその最も一般的な使用方法を理解するのに役立ちます。\n",
    "\n",
    "*コマンド ジョブ* を送信して、スクリプトの実行に必要な *ジョブ環境* で構成された指定の *コンピューティング リソース* で *トレーニング スクリプト* を実行する方法を学習します。\n",
    "\n",
    "トレーニング スクリプトはデータの準備を処理し、モデルのトレーニングと登録を行います。 モデルを取得したら、それを *エンドポイント* として *展開* し、*推論* のためにエンドポイントを呼び出します。\n",
    "\n",
    "手順は次のとおりです。\n",
    "\n",
    "> * Azure ML ワークスペースに接続する\n",
    "> * コンピューティング リソースとジョブ環境を作成する\n",
    "> * トレーニング スクリプトを作成する\n",
    "> * コマンド ジョブを作成して実行し、適切なジョブ環境で構成されたコンピューティング リソースでトレーニング スクリプトを実行します。\n",
    "> * トレーニング スクリプトの出力を表示する\n",
    "> * 新しくトレーニングされたモデルをエンドポイントとしてデプロイする\n",
    "> * 推論のために Azure ML エンドポイントを呼び出す\n",
    "<!-- # AzureML in a Day\n",
    "\n",
    "Learn how a data scientist uses Azure Machine Learning (Azure ML) to train a model, then use the model for prediction. This tutorial will help you become familiar with the core concepts of Azure ML and their most common usage. \n",
    "\n",
    "You'll learn how to submit a *command job* to run your *training script* on a specified *compute resource*, configured with the *job environment* necessary to run the script.\n",
    "\n",
    "The training script handles the data preparation, then trains and registers a model. Once you have the model, you'll *deploy* it as an *endpoint*, then call the endpoint for *inferencing*.\n",
    "\n",
    "The steps you'll take are:\n",
    "\n",
    "> * Connect to your Azure ML workspace\n",
    "> * Create your compute resource and job environment\n",
    "> * Create your training script\n",
    "> * Create and run your command job to run the training script on the compute resource, configured with the appropriate job environment\n",
    "> * View the output of your training script\n",
    "> * Deploy the newly-trained model as an endpoint\n",
    "> * Call the Azure ML endpoint for inferencing -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前提条件\n",
    "\n",
    "* Azure サブスクリプション。 Azure サブスクリプションをお持ちでない場合は、開始する前に [無料アカウントを作成](https://aka.ms/AMLFree) してください。\n",
    "* 作業中の Azure ML ワークスペース。 ワークスペースは、Azure ポータル、Azure CLI、または Python SDK を介して作成できます。 [詳細](https://docs.microsoft.com/azure/machine-learning/how-to-manage-workspace?tabs=python)。\n",
    "* Azure Machine Learning [ワークスペース]()\n",
    "* ワークスペースとコンピューティング インスタンス。[クイック スタート: Azure Machine Learning の使用を開始する](https://docs.microsoft.com/azure/machine-learning/quickstart-create-resources#create-compute-instance) を完了することで作成できます。\n",
    "<!-- ## Prerequisites\n",
    "\n",
    "* An Azure subscription. If you don't have an Azure subscription, [create a free account](https://aka.ms/AMLFree) before you begin.\n",
    "* A working Azure ML workspace. A workspace can be created via Azure Portal, Azure CLI, or Python SDK. [Read more](https://docs.microsoft.com/azure/machine-learning/how-to-manage-workspace?tabs=python).\n",
    "* An Azure Machine Learning [workspace]()\n",
    "* A workspace and compute instance which you can create by  completing the [Quickstart: Get started with Azure Machine Learning](https://docs.microsoft.com/azure/machine-learning/quickstart-create-resources#create-compute-instance) -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ワークスペースに接続する\n",
    "\n",
    "コードに飛び込む前に、Azure MLワークスペースに接続する必要があります。 ワークスペースは、Azure Machine Learningのトップレベルのリソースであり、Azure Machine Learningを使用するときに作成するすべてのアーティファクトを使用するための集中的な場所を提供します。\n",
    "\n",
    "`DefaultAzureCredential` を使用して、ワークスペースにアクセスしています。\n",
    "`DefaultAzurecredential` は、ほとんどのAzure SDK認証シナリオを処理するために使用されます。\n",
    "\n",
    "うまくいかない場合、さらなる利用可能な資格情報を参照してください：[資格情報を構成する例](../../configuration.ipynb) , [azure-identityリファレンスdoc](https://docs.microsoft.com/python/api/azure-identity/azure.identity?view=azure-python)\n",
    "<!-- ## Connect to the workspace\n",
    "\n",
    "Before you dive in the code, you'll need to connect to your Azure ML workspace. The workspace is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning.\n",
    "\n",
    "We're using `DefaultAzureCredential` to get access to workspace. \n",
    "`DefaultAzureCredential` is used to handle most Azure SDK authentication scenarios. \n",
    "\n",
    "Reference for more available credentials if it doesn't work for you: [configure credential example](../../configuration.ipynb), [azure-identity reference doc](https://docs.microsoft.com/python/api/azure-identity/azure.identity?view=azure-python). -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "credential"
   },
   "outputs": [],
   "source": [
    "# Handle to the workspace\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "# Authentication package\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ブラウザを使用してログインして認証する場合は、代わりに次のコードを使用できます。 この例では、 `DefaultAzureCredential` を使用します。\n",
    "<!-- If you want to use a browser to login and authenticate, you can use the following code instead. In this example, you'll use the `DefaultAzureCredential`. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle to the workspace\n",
    "# from azure.ai.ml import MLClient\n",
    "\n",
    "# Authentication package\n",
    "# from azure.identity import InteractiveBrowserCredential\n",
    "# credential = InteractiveBrowserCredential()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のセルで、サブスクリプションID、リソースグループ名、およびワークスペース名を入力します。 これらの値を見つけるには：\n",
    "\n",
    "1. 右上のAzure Machine Learning Studio Toolbarで、ワークスペース名を選択します。\n",
    "1. ワークスペース、リソースグループ、サブスクリプションIDの値をコードにコピーします。\n",
    "1. 1つの値をコピーし、領域を閉じて貼り付けてから、次の値に戻ってきます。\n",
    "\n",
    "![ワークスペース資格情報の画像](media/find-credentials.png)\n",
    "<!-- In the next cell, enter your Subscription ID, Resource Group name and Workspace name. To find these values:\n",
    "\n",
    "1. In the upper right Azure Machine Learning studio toolbar, select your workspace name.\n",
    "1. Copy the value for workspace, resource group and subscription ID into the code.  \n",
    "1. You'll need to copy one value, close the area and paste, then come back for the next one.\n",
    "\n",
    "![image of workspace credentials](media\\find-credentials.png) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "ml_client"
   },
   "outputs": [],
   "source": [
    "# Get a handle to the workspace\n",
    "ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=\"<SUBSCRIPTION_ID>\",\n",
    "    resource_group_name=\"<RESOURCE_GROUP>\",\n",
    "    workspace_name=\"<AML_WORKSPACE_NAME>\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "その結果、他のリソースやジョブを管理するために使用するワークスペースのハンドラーができます。\n",
    "\n",
    "> [!重要]\n",
    "> MLClient の作成は、ワークスペースに接続しません。 クライアントの初期化は lazy であり、コールする必要がある最初の時まで待ちます（以下のノートにおいて、それはコンピューティングの作成中に発生します）。\n",
    "<!-- The result is a handler to the workspace that you'll use to manage other resources and jobs.\n",
    "\n",
    "> [!IMPORTANT]\n",
    "> Creating MLClient will not connect to the workspace. The client initialization is lazy, it will wait for the first time it needs to make a call (in the notebook below, that will happen during compute creation). -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コンピューティングリソースを作成して、ジョブを実行する\n",
    "\n",
    "ノートブックを実行するために使用している計算リソースは既にあります。 しかし、トレーニングジョブを実行するために使用する別のタイプ、**コンピューティング クラスター** を追加します。 コンピューティングクラスターは、Linux または Windows OS を備えた単一もしくは複数ノードのマシン、または Spark のような特定のコンピューティングファブリックにすることができます。\n",
    "\n",
    "Linux コンピューティング クラスターをプロビジョニングします。 [VMサイズと価格の完全なリスト](https://azure.microsoft.com/pricing/details/machine-learning/) を参照してください。\n",
    "\n",
    "この例で必要なのは基本的なクラスターのみなので、2つの vCPU コア、7GB RAM を備えた Standard_DS3_v2モデルを使用します。\n",
    "<!-- ## Create a compute resource to run your job\n",
    "\n",
    "You already have a compute resource you're using to run the notebook.  But now you'll add another type, a **compute cluster** that you'll use to run your training job. The compute cluster can be single or multi-node machines with Linux or Windows OS, or a specific compute fabric like Spark.\n",
    "\n",
    "You'll provision a Linux compute cluster. See the [full list on VM sizes and prices](https://azure.microsoft.com/pricing/details/machine-learning/) .\n",
    "\n",
    "For this example, you only need a basic cluster, so you'll use a Standard_DS3_v2 model with 2 vCPU cores, 7-GB RAM. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "cpu_compute_target"
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "\n",
    "# Name assigned to the compute cluster\n",
    "cpu_compute_target = \"cpu-cluster\"\n",
    "\n",
    "try:\n",
    "    # let's see if the compute target already exists\n",
    "    cpu_cluster = ml_client.compute.get(cpu_compute_target)\n",
    "    print(\n",
    "        f\"You already have a cluster named {cpu_compute_target}, we'll reuse it as is.\"\n",
    "    )\n",
    "\n",
    "except Exception:\n",
    "    print(\"Creating a new cpu compute target...\")\n",
    "\n",
    "    # Let's create the Azure ML compute object with the intended parameters\n",
    "    cpu_cluster = AmlCompute(\n",
    "        name=cpu_compute_target,\n",
    "        # Azure ML Compute is the on-demand VM service\n",
    "        type=\"amlcompute\",\n",
    "        # VM Family\n",
    "        size=\"STANDARD_DS3_V2\",\n",
    "        # Minimum running nodes when there is no job running\n",
    "        min_instances=0,\n",
    "        # Nodes in cluster\n",
    "        max_instances=4,\n",
    "        # How many seconds will the node running after the job termination\n",
    "        idle_time_before_scale_down=180,\n",
    "        # Dedicated or LowPriority. The latter is cheaper but there is a chance of job termination\n",
    "        tier=\"Dedicated\",\n",
    "    )\n",
    "    print(\n",
    "        f\"AMLCompute with name {cpu_cluster.name} will be created, with compute size {cpu_cluster.size}\"\n",
    "    )\n",
    "    # Now, we pass the object to MLClient's create_or_update method\n",
    "    cpu_cluster = ml_client.compute.begin_create_or_update(cpu_cluster)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ジョブ環境を作成する\n",
    "\n",
    "コンピューティング クラスターで AzureML ジョブを実行するには、[環境](https://docs.microsoft.com/azure/machine-learning/concept-environments) が必要です。 環境には、ソフトウェアランタイムと、トレーニングを行うコンピューティングにインストールしたいライブラリがリストされています。 ローカルマシンの Python 環境に似ています。\n",
    "\n",
    "AzureML は、一般的なトレーニングや推論シナリオに役立つ多くのキュレーションされた環境または既製環境を提供します。 また、Docker イメージまたは conda 構成を使用して独自のカスタム環境を作成することもできます。\n",
    "\n",
    "この例では、conda YAML ファイルを使用して、ジョブのためのカスタム conda 環境を作成します。\n",
    "\n",
    "まず、ファイルを保存するディレクトリを作成します。\n",
    "<!-- ## Create a job environment\n",
    "\n",
    "To run your AzureML job on your compute cluster, you'll need an [environment](https://docs.microsoft.com/azure/machine-learning/concept-environments). An environment lists the software runtime and libraries that you want installed on the compute where you’ll be training. It's similar to your Python environment on your local machine.\n",
    "\n",
    "AzureML provides many curated or ready-made environments, which are useful for common training and inference scenarios. You can also create your own custom environments using a docker image, or a conda configuration.\n",
    "\n",
    "In this example, you'll create a custom conda environment for your jobs, using a conda yaml file.\n",
    "\n",
    "First, create a directory to store the file in. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "dependencies_dir"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dependencies_dir = \"./dependencies\"\n",
    "os.makedirs(dependencies_dir, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、dependencies ディレクトリにファイルを作成します。 以下のセルは、IPython magic を使用して、作成したばかりのディレクトリにファイルを書き込みます。\n",
    "<!-- Now, create the file in the dependencies directory. The cell below uses IPython magic to write the file into the directory you just created. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "write_model"
   },
   "outputs": [],
   "source": [
    "%%writefile {dependencies_dir}/conda.yml\n",
    "name: model-env\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.8\n",
    "  - numpy=1.21.2\n",
    "  - pip=21.2.4\n",
    "  - scikit-learn=0.24.2\n",
    "  - scipy=1.7.1\n",
    "  - pandas>=1.1,<1.2\n",
    "  - pip:\n",
    "    - inference-schema[numpy-support]==1.3.0\n",
    "    - xlrd==2.0.1\n",
    "    - mlflow== 1.26.1\n",
    "    - azureml-mlflow==1.42.0\n",
    "    - psutil>=5.8,<5.9\n",
    "    - tqdm>=4.59,<4.60\n",
    "    - ipykernel~=6.0\n",
    "    - matplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この指定内容には、ジョブ（numpy、pip）で使用するいくつかの通常のパッケージが含まれています。\n",
    "\n",
    "この *yaml* ファイルを参照して、このカスタム環境をワークスペースに作成および登録します。\n",
    "<!-- \n",
    "The specification contains some usual packages, that you'll use in your job (numpy, pip).\n",
    "\n",
    "Reference this *yaml* file to create and register this custom environment in your workspace: -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "custom_env_name"
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "custom_env_name = \"aml-scikit-learn\"\n",
    "\n",
    "pipeline_job_env = Environment(\n",
    "    name=custom_env_name,\n",
    "    description=\"Custom environment for Credit Card Defaults pipeline\",\n",
    "    tags={\"scikit-learn\": \"0.24.2\"},\n",
    "    conda_file=os.path.join(dependencies_dir, \"conda.yml\"),\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:latest\",\n",
    ")\n",
    "pipeline_job_env = ml_client.environments.create_or_update(pipeline_job_env)\n",
    "\n",
    "print(\n",
    "    f\"Environment with name {pipeline_job_env.name} is registered to workspace, the environment version is {pipeline_job_env.version}\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コマンドジョブとは何か？\n",
    "\n",
    "Azure ML *コマンドジョブ* を作成して、クレジット債務不履行の予測モデルをトレーニングします。 コマンドジョブは、指定された計算リソース上の指定された環境で *トレーニングスクリプト* を実行するために使用されます。 すでに環境と計算リソースを作成しました。 次に、トレーニングスクリプトを作成します。\n",
    "\n",
    "*トレーニングスクリプト* は、トレーニングされたモデルのデータ準備、トレーニング、登録を処理します。 このチュートリアルでは、Python トレーニングスクリプトを作成します。\n",
    "\n",
    "コマンドジョブは、CLI、Python SDK、または Studio インターフェイスから実行できます。 このチュートリアルでは、Azure ML Python SDK v2 を使用してコマンドジョブを作成および実行します。\n",
    "\n",
    "トレーニングジョブを実行した後、モデルをデプロイし、それを使用して予測値を生成します。\n",
    "<!-- ## What is a command job?\n",
    "\n",
    "You'll create an Azure ML *command job* to train a model for credit default prediction. The command job is used to run a *training script* in a specified environment on a specified compute resource.  You've already created the environment and the compute resource.  Next you'll create the training script.\n",
    "\n",
    "The *training script* handles the data preparation, training and registering of the trained model. In this tutorial, you'll create a Python training script.\n",
    "\n",
    "Command jobs can be run from CLI, Python SDK, or studio interface. In this tutorial, you'll use the Azure ML Python SDK v2 to create and run the command job.\n",
    "\n",
    "After running the training job, you'll deploy the model, then use it to produce a prediction. -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## トレーニングスクリプトを作成する\n",
    "\n",
    "トレーニングスクリプト (*main.py* Python ファイル) を作成することから始めましょう。\n",
    "\n",
    "最初にスクリプトのソースフォルダーを作成します。\n",
    "<!-- ## Create training script\n",
    "\n",
    "Let's start by creating the training script - the *main.py* Python file.\n",
    "\n",
    "First create a source folder for the script: -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "train_src_dir"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_src_dir = \"./src\"\n",
    "os.makedirs(train_src_dir, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このスクリプトは、データの前処理を処理し、テストとトレーニングデータに分割します。 次に、このデータを消費してツリーベースのモデルをトレーニングし、出力モデルを返します。\n",
    "\n",
    "[MLFlow](https://learn.microsoft.com/azure/machine-learning/how-to-log-mlflow-models) は、パイプラインの実行中にパラメーターとメトリックを記録するために使用されます。\n",
    "\n",
    "以下のセルは、IPython magic を使用して、作成したばかりのディレクトリにトレーニングスクリプトを書き込みます。\n",
    "<!-- This script handles the preprocessing of the data, splitting it into test and train data. It then consumes this data to train a tree based model and return the output model. \n",
    "\n",
    "[MLFlow](https://learn.microsoft.com/azure/machine-learning/how-to-log-mlflow-models) will be used to log the parameters and metrics during our pipeline run. \n",
    "\n",
    "The cell below uses IPython magic to write the training script into the directory you just created. -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "write_main"
   },
   "outputs": [],
   "source": [
    "%%writefile {train_src_dir}/main.py\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function of the script.\"\"\"\n",
    "\n",
    "    # input and output arguments\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data\", type=str, help=\"path to input data\")\n",
    "    parser.add_argument(\"--test_train_ratio\", type=float, required=False, default=0.25)\n",
    "    parser.add_argument(\"--n_estimators\", required=False, default=100, type=int)\n",
    "    parser.add_argument(\"--learning_rate\", required=False, default=0.1, type=float)\n",
    "    parser.add_argument(\"--registered_model_name\", type=str, help=\"model name\")\n",
    "    args = parser.parse_args()\n",
    "   \n",
    "    # Start Logging\n",
    "    mlflow.start_run()\n",
    "\n",
    "    # enable autologging\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    ###################\n",
    "    #<prepare the data>\n",
    "    ###################\n",
    "    print(\" \".join(f\"{k}={v}\" for k, v in vars(args).items()))\n",
    "\n",
    "    print(\"input data:\", args.data)\n",
    "    \n",
    "    credit_df = pd.read_excel(args.data, header=1, index_col=0)\n",
    "\n",
    "    mlflow.log_metric(\"num_samples\", credit_df.shape[0])\n",
    "    mlflow.log_metric(\"num_features\", credit_df.shape[1] - 1)\n",
    "\n",
    "    train_df, test_df = train_test_split(\n",
    "        credit_df,\n",
    "        test_size=args.test_train_ratio,\n",
    "    )\n",
    "    ####################\n",
    "    #</prepare the data>\n",
    "    ####################\n",
    "\n",
    "    ##################\n",
    "    #<train the model>\n",
    "    ##################\n",
    "    # Extracting the label column\n",
    "    y_train = train_df.pop(\"default payment next month\")\n",
    "\n",
    "    # convert the dataframe values to array\n",
    "    X_train = train_df.values\n",
    "\n",
    "    # Extracting the label column\n",
    "    y_test = test_df.pop(\"default payment next month\")\n",
    "\n",
    "    # convert the dataframe values to array\n",
    "    X_test = test_df.values\n",
    "\n",
    "    print(f\"Training with data of shape {X_train.shape}\")\n",
    "\n",
    "    clf = GradientBoostingClassifier(\n",
    "        n_estimators=args.n_estimators, learning_rate=args.learning_rate\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    ###################\n",
    "    #</train the model>\n",
    "    ###################\n",
    "\n",
    "    ##########################\n",
    "    #<save and register model>\n",
    "    ##########################\n",
    "    # Registering the model to the workspace\n",
    "    print(\"Registering the model via MLFlow\")\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=clf,\n",
    "        registered_model_name=args.registered_model_name,\n",
    "        artifact_path=args.registered_model_name,\n",
    "    )\n",
    "\n",
    "    # Saving the model to a file\n",
    "    mlflow.sklearn.save_model(\n",
    "        sk_model=clf,\n",
    "        path=os.path.join(args.registered_model_name, \"trained_model\"),\n",
    "    )\n",
    "    ###########################\n",
    "    #</save and register model>\n",
    "    ###########################\n",
    "    \n",
    "    # Stop Logging\n",
    "    mlflow.end_run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このスクリプトでわかるように、モデルがトレーニングされると、モデルファイルが保存され、ワークスペースに登録されます。 これで、登録したモデルを推論のエンドポイントで使用できます。\n",
    "\n",
    "## コマンドを構成する\n",
    "\n",
    "目的のタスクを実行できるスクリプトができたので、コマンドラインアクションを実行できる汎用の **コマンド** を使用します。 このコマンドラインのアクションは、システムコマンドを直接呼び出すか、スクリプトを実行することによってできます。\n",
    "\n",
    "ここでは、入力変数を作成して、入力データ、分割比、学習レート、登録モデル名を指定します。 コマンドスクリプトは次のとおりです。\n",
    "* 以前に作成された計算を使用して、このコマンドを実行します。\n",
    "* 以前に作成された環境を使用します - `@latest` 表記を使用して、コマンドが実行されたときに最新バージョンの環境を示すことができます。\n",
    "* ディスプレイ名、実験名などのメタデータを構成します。 *実験* は、特定のプロジェクトで行うすべての反復のコンテナです。 同じ実験名で提出されたすべてのジョブは、Azure ML Studio において順番にリストされます。\n",
    "* コマンドラインアクションそのもの、このケースでは `python main.py` を構成します。 入力/出力は、コマンド内で `${{ ... }}` 表記を介してアクセスできます。\n",
    "* このサンプルでは、インターネット上のファイルから取得したデータにアクセスします。\n",
    "<!-- As you can see in this script, once the model is trained, the model file is saved and registered to the workspace. Now you can use the registered model in inferencing endpoints.\n",
    "\n",
    "## Configure the command\n",
    "\n",
    "Now that you have a script that can perform the desired tasks, you'll use the general purpose **command** that can run command line actions. This command line action can be directly calling system commands or by running a script. \n",
    "\n",
    "Here, you'll create input variables to specify the input data, split ratio, learning rate and registered model name.  The command script will:\n",
    "* Use the compute created earlier to run this command.\n",
    "* Use the environment created earlier - you can use the `@latest` notation to indicate the latest version of the environment when the command is run.\n",
    "* Configure some metadata like display name, experiment name etc. An *experiment* is a container for all the iterations you do on a certain project. All the jobs submitted under the same experiment name would be listed next to each other in Azure ML studio.\n",
    "* Configure the command line action itself - `python main.py` in this case. The inputs/outputs are accessible in the command via the `${{ ... }}` notation.\n",
    "* In this sample, we access the data from a file on the internet.  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "registered_model_name"
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "from azure.ai.ml import Input\n",
    "\n",
    "registered_model_name = \"credit_defaults_model\"\n",
    "\n",
    "job = command(\n",
    "    inputs=dict(\n",
    "        data=Input(\n",
    "            type=\"uri_file\",\n",
    "            path=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00350/default%20of%20credit%20card%20clients.xls\",\n",
    "        ),\n",
    "        test_train_ratio=0.2,\n",
    "        learning_rate=0.25,\n",
    "        registered_model_name=registered_model_name,\n",
    "    ),\n",
    "    code=\"./src/\",  # location of source code\n",
    "    command=\"python main.py --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} --learning_rate ${{inputs.learning_rate}} --registered_model_name ${{inputs.registered_model_name}}\",\n",
    "    environment=\"aml-scikit-learn@latest\",\n",
    "    compute=\"cpu-cluster\",\n",
    "    experiment_name=\"train_model_credit_default_prediction\",\n",
    "    display_name=\"credit_default_prediction\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ジョブを提出する\n",
    "\n",
    "今こそ、AzureML で実行するジョブを提出する時が来ました。 今回は、 `ml_client.jobs` で `create_or_update` を使用します。\n",
    "<!-- ## Submit the job \n",
    "\n",
    "It's now time to submit the job to run in AzureML. This time you'll use `create_or_update`  on `ml_client.jobs`. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "create_job"
   },
   "outputs": [],
   "source": [
    "ml_client.create_or_update(job)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ジョブの出力を表示し、ジョブの完了を待つ\n",
    "\n",
    "前のセルの出力のリンクを選択して、Azure ML Studio でジョブを表示します。\n",
    "\n",
    "このジョブの出力は、Azure ML Studio でこのようになります。 メトリック、出力などのさまざまな詳細については、タブを探索します。完了すると、ジョブはトレーニングの結果としてワークスペースにモデルを登録します。\n",
    "\n",
    "![ジョブの概要を示すスクリーンショット](media/view-job.gif \"View the job in studio\")\n",
    "\n",
    "> [!重要]\n",
    "> ジョブのステータスが完了するまで待ってから、このノートブックに戻って続行します。 ジョブの実行には 2〜3 分かかります。 コンピューティング クラスターがゼロノードにスケーリングされ、カスタム環境がまだ構築中である場合は、より長く（最大10分）かかります。\n",
    "<!-- ## View job output and wait for job completion\n",
    "\n",
    "View the job in Azure ML studio by selecting the link in the output of the previous cell. \n",
    "\n",
    "The output of this job will look like this in Azure ML studio. Explore the tabs for various details like metrics, outputs etc. Once completed, the job will register a model in your workspace as a result of training. \n",
    "\n",
    "![Screenshot that shows the job overview](media/view-job.gif \"View the job in studio\")\n",
    "\n",
    "> [!IMPORTANT]\n",
    "> Wait until the status of the job is complete before returning to this notebook to continue. The job will take 2 to 3 minutes to run. It could take longer (up to 10 minutes) if the compute cluster has been scaled down to zero nodes and custom environment is still building.\n",
    " -->\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## オンラインエンドポイントとしてモデルを展開する\n",
    "\n",
    "次に、Azure Cloud、[`online endpoint`](https://docs.microsoft.com/azure/machine-learning/concept-encept-endpoints) でWebサービスとして機械学習モデルをデプロイします。\n",
    "\n",
    "機械学習サービスをデプロイするには、通常以下のことが必要です:\n",
    "\n",
    "* 展開するモデル資産（ファイル、メタデータ）。 これらの資産はすでにトレーニングジョブに登録しています。\n",
    "* サービスとして実行するコード。 コードは、渡された入力要求に基づいてモデルを実行します。 このエントリー スクリプトは、デプロイされた Web サービスに送信されたデータを受信してモデルに渡し、モデルのレスポンスをクライアントに返します。 スクリプトはモデルに固有です。 エントリー スクリプトは、モデルが期待して返すデータを理解する必要があります。 このチュートリアルのように、MLFlow モデルを使用すると、このスクリプトは自動的に作成されます。 スコアリングスクリプトのサンプルは[こちら](https://github.com/azure/azureml-examples/tree/sdk-preview/sdk/endpoints/online) で見つけることができます。\n",
    "<!-- ## Deploy the model as an online endpoint\n",
    "\n",
    "Now deploy your machine learning model as a web service in the Azure cloud, an [`online endpoint`](https://docs.microsoft.com/azure/machine-learning/concept-endpoints).\n",
    "\n",
    "To deploy a machine learning service, you usually need:\n",
    "\n",
    "* The model assets (file, metadata) that you want to deploy. You've already registered these assets in your training job.\n",
    "* Some code to run as a service. The code executes the model on a given input request. This entry script receives data submitted to a deployed web service and passes it to the model, then returns the model's response to the client. The script is specific to your model. The entry script must understand the data that the model expects and returns. With an MLFlow model, as in this tutorial, this script is automatically created for you. Samples of scoring scripts can be found [here](https://github.com/Azure/azureml-examples/tree/sdk-preview/sdk/endpoints/online). -->\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新しいオンラインエンドポイントを作成する\n",
    "\n",
    "登録モデルと推論スクリプトができたので、オンラインエンドポイントを作成する時が来ました。 エンドポイント名は、Azure の全リージョンで一意である必要があります。 このチュートリアルでは [`UUID`](https://en.wikipedia.org/wiki/Universally_unique_identifier) を使用して一意の名前を作成します。\n",
    "<!-- ## Create a new online endpoint\n",
    "\n",
    "Now that you have a registered model and an inference script, it's time to create your online endpoint. The endpoint name needs to be unique in the entire Azure region. For this tutorial, you'll create a unique name using [`UUID`](https://en.wikipedia.org/wiki/Universally_unique_identifier#:~:text=A%20universally%20unique%20identifier%20(UUID,%2C%20for%20practical%20purposes%2C%20unique.). -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "online_endpoint_name"
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Creating a unique name for the endpoint\n",
    "online_endpoint_name = \"credit-endpoint-\" + str(uuid.uuid4())[:8]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> エンドポイントの作成には約6〜8分かかることを想定してください。\n",
    "<!-- > [!NOTE]\n",
    "> Expect the endpoint creation to take approximately 6 to 8 minutes. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "endpoint"
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Model,\n",
    "    Environment,\n",
    ")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=\"this is an online endpoint\",\n",
    "    auth_mode=\"key\",\n",
    "    tags={\n",
    "        \"training_dataset\": \"credit_defaults\",\n",
    "        \"model_type\": \"sklearn.GradientBoostingClassifier\",\n",
    "    },\n",
    ")\n",
    "\n",
    "endpoint = ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "\n",
    "print(f\"Endpoint {endpoint.name} provisioning state: {endpoint.provisioning_state}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エンドポイントを作成したら、以下のようにそれを取得できます。\n",
    "<!-- Once you've created an endpoint, you can retrieve it as below: -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "retrieve_endpoint"
   },
   "outputs": [],
   "source": [
    "endpoint = ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "print(\n",
    "    f'Endpoint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## エンドポイントにモデルを展開する\n",
    "\n",
    "エンドポイントが作成されたら、エントリースクリプトでモデルをデプロイします。 各エンドポイントには複数のデプロイが可能です。 これらのデプロイへの直接的なトラフィックは、ルールを使用して指定できます。 ここでは、受信トラフィックの 100％ を処理する単一のデプロイを作成します。 任意ではありますが、たとえば *ブルー*、 *グリーン*、 *レッド* デプロイなど、カラー名を選択しました。\n",
    "\n",
    "Azure ML studio の **モデル** ページを確認して、登録モデルの最新バージョンを特定できます。 または、以下のコードによって、使用する最新バージョン番号を取得します。\n",
    "<!-- ## Deploy the model to the endpoint\n",
    "\n",
    "Once the endpoint is created, deploy the model with the entry script. Each endpoint can have multiple deployments. Direct traffic to these deployments can be specified using rules. Here you'll create a single deployment that handles 100% of the incoming traffic. We have chosen a color name for the deployment, for example, *blue*, *green*, *red* deployments, which is arbitrary.\n",
    "\n",
    "You can check the **Models** page on Azure ML studio, to identify the latest version of your registered model. Alternatively, the code below will retrieve the latest version number for you to use. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "latest_model_version"
   },
   "outputs": [],
   "source": [
    "# Let's pick the latest version of the model\n",
    "latest_model_version = max(\n",
    "    [int(m.version) for m in ml_client.models.list(name=registered_model_name)]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルの最新バージョンをデプロイします。\n",
    "\n",
    "> [!NOTE]\n",
    "> この展開には約 6〜8 分かかることを想定してください。\n",
    "<!-- Deploy the latest version of the model.  \n",
    "\n",
    "> [!NOTE]\n",
    "> Expect this deployment to take approximately 6 to 8 minutes. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "blue_deployment"
   },
   "outputs": [],
   "source": [
    "# picking the model to deploy. Here we use the latest version of our registered model\n",
    "model = ml_client.models.get(name=registered_model_name, version=latest_model_version)\n",
    "\n",
    "\n",
    "# create an online deployment.\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=model,\n",
    "    instance_type=\"Standard_DS3_v2\",\n",
    "    instance_count=1,\n",
    ")\n",
    "\n",
    "blue_deployment = ml_client.begin_create_or_update(blue_deployment).result()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### サンプルクエリを使用したテスト\n",
    "\n",
    "モデルがエンドポイントにデプロイされたので、推論を実行できます。\n",
    "\n",
    "スコアスクリプトにおける run メソッドで期待される設計に従って、サンプル リクエストのファイルを作成します。\n",
    "<!-- ### Test with a sample query\n",
    "\n",
    "Now that the model is deployed to the endpoint, you can run inference with it.\n",
    "\n",
    "Create a sample request file following the design expected in the run method in the score script. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "deploy_dir"
   },
   "outputs": [],
   "source": [
    "deploy_dir = \"./deploy\"\n",
    "os.makedirs(deploy_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "write_sample"
   },
   "outputs": [],
   "source": [
    "%%writefile {deploy_dir}/sample-request.json\n",
    "{\n",
    "  \"input_data\": {\n",
    "    \"columns\": [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22],\n",
    "    \"index\": [0, 1],\n",
    "    \"data\": [\n",
    "            [20000,2,2,1,24,2,2,-1,-1,-2,-2,3913,3102,689,0,0,0,0,689,0,0,0,0],\n",
    "            [10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 10, 9, 8]\n",
    "        ]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "test"
   },
   "outputs": [],
   "source": [
    "# test the blue deployment with some sample data\n",
    "ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    request_file=\"./deploy/sample-request.json\",\n",
    "    deployment_name=\"blue\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## リソースをクリーンアップする\n",
    "\n",
    "エンドポイントを使用しない場合は、削除してリソースの使用を停止します。 削除する前に、他のデプロイがエンドポイントを使用していないことを確認してください。\n",
    "\n",
    "\n",
    "> [!NOTE]\n",
    "> このステップには約 6〜8 分かかることを想定してください。\n",
    "<!-- ## Clean up resources\n",
    "\n",
    "If you're not going to use the endpoint, delete it to stop using the resource.  Make sure no other deployments are using an endpoint before you delete it.\n",
    "\n",
    "\n",
    "> [!NOTE]\n",
    "> Expect this step to take approximately 6 to 8 minutes. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "name": "delete_endpoint"
   },
   "outputs": [],
   "source": [
    "ml_client.online_endpoints.begin_delete(name=online_endpoint_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 次のステップ\n",
    "\n",
    "このスクリプト用のマルチ ステップ パイプラインの作成について学ぶ。 [jupyter ノートブックでプロダクション用 ML パイプラインを作成](https://github.com/Azure/azureml-examples/blob/main/tutorials/e2e-ds-experience/e2e-ml-workflow.ipynb)\n",
    "<!-- ## Next Steps\n",
    "\n",
    "Learn about creating a multi step pipeline for this script [Create production ML pipelines in a Jupyter notebook](https://github.com/Azure/azureml-examples/blob/main/tutorials/e2e-ds-experience/e2e-ml-workflow.ipynb). -->"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Learn how a data scientist uses Azure Machine Learning (Azure ML) to train a model, then use the model for prediction. This tutorial will help you become familiar with the core concepts of Azure ML and their most common usage."
  },
  "kernelspec": {
   "display_name": "Python 3.10 - SDK V2",
   "language": "python",
   "name": "python310-sdkv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "71a65d72c50a26f05c9d6876d6234594cb07dd1b273faf1eea7eaa26341f62bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
